\textbf{Explica brevemente qué es el problema del significado (The Problem of Meaning) en la inteligencia artificial. Cita tus fuentes (1 pt.).}\vspace{.3cm}

La siguiente explicación se basa mayoritariamente en el artículo de~\cite{philosophies4020014}. La manera más sencilla para mí de entenderlo es observar la diferencia entre lo que representa una operación como \textit{x=2+2} para nosotros y para las computadoras (sistemas inteligentes). De entrada, si no sabemos álgebra, este conjunto de símbolos no significa nada; es decir, solo son letras con números relacionados por un símbolo raro. Usualmente, nos enseñan cómo funcionan este tipo de operaciones con ejemplos de la vida real. Por ejemplo, la operación \textit{x=2+2} significa que si tienes 2 manzanas y tu amigo tiene otras 2 manzanas, juntos tienen 4 manzanas, o lo que es lo mismo, \textit{x} vale 4.\vspace{.3cm}

Es obvio, entonces, que para nosotros la operación por sí misma básicamente no tiene sentido, o mejor dicho, tiene sentido una vez que entendemos su significado y lo abstraemos usando matemáticas. Ahora, podemos comparar este comportamiento con el de una máquina al ver esta operación. Para la máquina, esta operación nativamente tiene "sentido": \textit{x=2+2} no es más que una serie de, digamos, tokens que al final del día están asociados con un comportamiento preprogramado que le indica qué hacer. Incluso así, el programa no sabe realmente que está sumando dos números; más bien, sigue una serie de pasos hasta el nivel de los transistores, manipulando su memoria hasta llegar al resultado. Como se menciona en el artículo citado, si lo que se está sumando son manzanas, personas u horas, esto no hace ninguna diferencia para la ejecución del programa. Sin embargo, es obvio que para nosotros sí hace diferencia: no solo podemos tomar decisiones en base a lo que estamos viendo, sino que además podemos preguntarnos "¿qué significa lo que estamos haciendo?".\vspace{.3cm}

Esto último es lo que más caracteriza la diferencia entre nosotros y estos sistemas. Al final del día, el comportamiento y la lógica de estos sistemas, por más "inteligentes" que sean, no constituyen un entendimiento fundamental de los sucesos, sino algo más parecido a una tabla extremadamente grande de posibles respuestas y métodos matemáticos para intentar obtener la mejor de ellas. Lo cual, por cierto, no es algo necesariamente malo, ya que cuando se trata de cuestiones no subjetivas o que dependen más de la sintaxis que del significado, estos sistemas suelen ser más eficientes.